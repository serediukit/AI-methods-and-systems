{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "from keras.layers import Convolution2D, BatchNormalization, MaxPooling2D, Dense, Input, Dropout, Flatten\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "import pandas as pd\n",
    "from keras.callbacks import TensorBoard\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Wav_(WorkDir):\n",
    "    Input_Files = []\n",
    "    Source_Samples= []\n",
    "    for d, dirs, files in os.walk(WorkDir):\n",
    "        for file in files:\n",
    "            Input_Files.append(file)\n",
    "    GFile  = []\n",
    "    for file in Input_Files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                sample_rate, samples = wavfile.read(str(WorkDir)+ file)\n",
    "                if sample_rate != 8000:\n",
    "                    continue\n",
    "                if max(abs(samples)) < 410:\n",
    "                    continue\n",
    "                if len(samples) < int(0.1 * sample_rate):\n",
    "                    continue\n",
    "                GFile.append(file)\n",
    "#                 samples = Convert_To_06(samples)\n",
    "                Source_Samples.append(samples)\n",
    "\n",
    "    return  Source_Samples, GFile\n",
    "\n",
    "\n",
    "\n",
    "def Add_Zero(specgram, TargetColumnNumber, StartSignalPosition):\n",
    "\n",
    "    if len(specgram[0]) >= TargetColumnNumber:\n",
    "         return specgram\n",
    "\n",
    "    full_array = np.zeros((len(specgram), TargetColumnNumber))\n",
    "    full_array[:, :len(specgram[0])-TargetColumnNumber] = specgram\n",
    "    if StartSignalPosition == 0:\n",
    "        full_array[:, :len(specgram[0]) - TargetColumnNumber] = specgram\n",
    "    elif StartSignalPosition == TargetColumnNumber - len(specgram[0]):\n",
    "        full_array[:, StartSignalPosition:] = specgram\n",
    "    else:\n",
    "        full_array[:, StartSignalPosition:StartSignalPosition+len(specgram[0]) - TargetColumnNumber] = specgram\n",
    "\n",
    "    return full_array\n",
    "def log_specgram(audio, window_size, sample_rate=8000,\n",
    "                 eps=1e-10, windoe_fuction='hann'):\n",
    "    nperseg = int(round(window_size * sample_rate / 1000))\n",
    "    noverlap = int(round(window_size / 2 * sample_rate / 1000))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                            fs=sample_rate,\n",
    "                                            window=windoe_fuction,\n",
    "                                            nperseg=nperseg,\n",
    "                                            noverlap=noverlap,\n",
    "                                            detrend=False)\n",
    "    return freqs, times, np.log(spec.astype(np.float32) + eps)\n",
    "def Convert_Wav_To_specgram(SamplesList, Input_Files, window_size, windoe_fuction):\n",
    "    samples = np.zeros(int(0.6 * 8000))\n",
    "    _, _, specgram = log_specgram(audio=samples, window_size=window_size, windoe_fuction=windoe_fuction)\n",
    "    TargetColumnNumber = len(specgram[0])\n",
    "    TargetRow = len(specgram)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(SamplesList)):\n",
    "        _, _, specgram = log_specgram(audio=SamplesList[i], window_size=window_size, windoe_fuction=windoe_fuction)\n",
    "        specgram = Add_Zero(specgram, TargetColumnNumber, 0)\n",
    "        x.append(specgram)\n",
    "        file = Input_Files[i]\n",
    "        if 'cl_1' in file:\n",
    "            y.append([0, 0, 1])\n",
    "        elif 'cl_2' in file:\n",
    "            y.append([1, 0, 0])\n",
    "        else:\n",
    "            y.append([0, 1, 0])\n",
    "        \n",
    " \n",
    "    x = np.array(x)\n",
    "    x = x.reshape(tuple(list(x.shape) + [1]))\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "def RandomozeArrays(SourceArrayX, SourceArrayY):\n",
    "    TargetArrayX=[]\n",
    "    TargetArrayY=[]\n",
    "    while 0 < len(SourceArrayX):\n",
    "        Index = random.randint(0, len(SourceArrayX) - 1)\n",
    "        TargetArrayX.append(SourceArrayX[Index])\n",
    "        del SourceArrayX[Index]\n",
    "        TargetArrayY.append(SourceArrayY[Index])\n",
    "        del SourceArrayY[Index]      \n",
    "        \n",
    "    return TargetArrayX,TargetArrayY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learn_NN_5L_(TrainDir,ValidDir, RezDir,NN_Name,Epochs=30, window_size=25, windoe_fuction='hann'):\n",
    "    Source_Samples, Input_Files= Load_Wav_(TrainDir)\n",
    "    print('end load train data', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    Source_Samples, Input_Files = RandomozeArrays(Source_Samples, Input_Files)\n",
    "    print('end Randomize train data', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "    \n",
    "    \n",
    "    X_Train, Y_Train = Convert_Wav_To_specgram(SamplesList=Source_Samples, Input_Files=Input_Files,\n",
    "                                           window_size=window_size, windoe_fuction=windoe_fuction)\n",
    "    print('end convert train data', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "     \n",
    "    Source_Samples, Input_Files = Load_Wav_(ValidDir)\n",
    "    print('end load valid data', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "\n",
    "    X_val1, y_val1 = Convert_Wav_To_specgram(SamplesList=Source_Samples, Input_Files=Input_Files,\n",
    "                                                     window_size=window_size, windoe_fuction=windoe_fuction)\n",
    "    print('end convert valid data', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "\n",
    "    input_shape = (X_Train.shape[1], X_Train.shape[2], 1)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_shape = input_shape))\n",
    "    model.add(Convolution2D(48, (5, 5), strides = (3, 3), padding = 'same',input_shape = input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(40, (3, 3), strides = (2, 2), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "#     model.add(Dense(45))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dense(30))\n",
    "#     model.add(Activation('relu'))\n",
    "    model.add(Dense(15))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    csv_logger = CSVLogger(RezDir+NN_Name+'_training__log.csv', separator=',', append=False)\n",
    "\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath=RezDir+NN_Name+'_Best.hdf5',\n",
    "                 monitor='val_accuracy',\n",
    "                 save_best_only=True,\n",
    "                 mode='max',\n",
    "                 verbose=1)\n",
    "    model.fit(X_Train, Y_Train,\n",
    "          batch_size = 64,\n",
    "          epochs = Epochs,shuffle=True,\n",
    "          validation_data=(X_val1, y_val1),\n",
    "          callbacks=[checkpoint, csv_logger])\n",
    "    model.save(filepath=RezDir+NN_Name+'_Final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TestNN_(NetName, SourceDir, TargetFile, window_size):\n",
    "    Input_Files = []\n",
    "    Source_Samples = []\n",
    "    for d, dirs, files in os.walk(SourceDir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                sample_rate, samples = wavfile.read(SourceDir + file)\n",
    "                if sample_rate != 8000:\n",
    "                     continue\n",
    "                if max(abs(samples)) < 410:\n",
    "                    continue\n",
    "                if len(samples) < int(0.1 * sample_rate):\n",
    "                    continue\n",
    "                Input_Files.append(file)\n",
    "#                 samples = Convert_To_06(samples)\n",
    "                Source_Samples.append(samples)\n",
    "\n",
    "    x, y = Convert_Wav_To_specgram(SamplesList=Source_Samples, Input_Files=Input_Files,\n",
    "                                             window_size=window_size, windoe_fuction='hann')\n",
    "\n",
    "    new_model = load_model(NetName)\n",
    "    pred = new_model.predict(x)\n",
    "    f = open(TargetFile+'_FilesReport.csv', 'w', newline='\\n')\n",
    "    f.write('NetName = %s, Files %s \\n'%(NetName,SourceDir))\n",
    "    f.write('File Name,Marked As,Recognized As,Cl 1,Cl 2,Cl 3, \\n')\n",
    "    CodeList = ['Cl 2', 'Cl 3', 'Cl 1']\n",
    "    SemplCount= [0,0,0]\n",
    "    StatRez = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "    for i in range(len(pred)):\n",
    "        YY = list(y[i])\n",
    "        Rez = list(pred[i])\n",
    "        TrueCalss = YY.index(max(YY))\n",
    "        NNClass = Rez.index(max(Rez))\n",
    "        SemplCount[TrueCalss] +=1\n",
    "        StatRez[TrueCalss][NNClass] += 1\n",
    "        f.write( '%s,%s,%s, %f , %f, %f,\\n' % (Input_Files[i], CodeList[TrueCalss], CodeList[NNClass], pred[i][2], pred[i][0], pred[i][1]))\n",
    "\n",
    "    f.close()\n",
    "    f = open(TargetFile+'_Report.csv', 'w', newline='\\n')\n",
    "    f.write('NetName = %s, Files %s \\n'%(NetName,SourceDir))\n",
    "    f.write('Var,Cl 1,Cl 2,Cl 3, \\n')\n",
    "\n",
    "    f.write(  'Count,%s,%s, %s ,\\n' % (SemplCount[2],SemplCount[0], SemplCount[1]))\n",
    "    f.write('Cl 1 As,%s,%s, %s ,\\n' % (StatRez[2][2], StatRez[2][0], StatRez[2][1]))\n",
    "    f.write('Cl 2 As,%s,%s, %s ,\\n' % (StatRez[0][2], StatRez[0][0], StatRez[0][1]))\n",
    "    f.write('Cl 3 As,%s,%s, %s ,\\n' % (StatRez[1][2], StatRez[1][0], StatRez[1][1]))\n",
    "    trueclass =100.0* (StatRez[2][2] + StatRez[0][0] + StatRez[1][1])/ float( sum(SemplCount))\n",
    "    \n",
    "    for i in range(len(SemplCount)):\n",
    "        for k in range(len(SemplCount)):\n",
    "            if SemplCount[i] > 0:\n",
    "                StatRez[i][k]=100.0*float(StatRez[i][k])/SemplCount[i]\n",
    "    f.write('Cl 1 As %%,%.3f%%,%.3f%%, %.3f%% ,\\n' % (StatRez[2][2], StatRez[2][0], StatRez[2][1]))\n",
    "    f.write('Cl 2  As %%,%.3f%%,%.3f%%, %.3f%% ,\\n' % (StatRez[0][2], StatRez[0][0], StatRez[0][1]))\n",
    "    f.write('Cl 3 As %%,%.3f%%,%.3f%%, %.3f%% ,\\n' % (StatRez[1][2], StatRez[1][0], StatRez[1][1]))\n",
    "    \n",
    "    f.write(',\\n')\n",
    "    \n",
    "    f.write('Total acc. ,%.3f%% ,\\n' % (trueclass))\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---start Learn---', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "Learn_NN_5L_(TrainDir='e:\\Sasha\\Shevchenko\\Lekcii\\PracticalTraining/Train/', \n",
    "             ValidDir='e:\\Sasha\\Shevchenko\\Lekcii\\PracticalTraining/valid/', \n",
    "             RezDir='e:\\Sasha\\Shevchenko\\Lekcii\\PracticalTraining/Rez_dir/', \n",
    "             NN_Name='NN_L5', Epochs=5, window_size=25, windoe_fuction='hann')\n",
    "\n",
    "print('---end  Learn---', time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestNN_(NetName=r'e:\\Sasha\\Shevchenko\\Lekcii\\PracticalTraining/Rez_dir/NN_L5_Best.hdf5',\n",
    "            SourceDir=r'e:\\Sasha\\Shevchenko\\Lekcii\\PracticalTraining/test/',\n",
    "            TargetFile='e:\\Sasha\\Shevchenko\\Lekcii\\PracticalTraining/Rez_dir/NN_L5_rez',\n",
    "            window_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.10.0\n",
      "argon2-cffi==20.1.0\n",
      "astor==0.8.1\n",
      "attrs==20.2.0\n",
      "backcall==0.2.0\n",
      "bleach==3.1.5\n",
      "cachetools==4.1.1\n",
      "certifi==2020.6.20\n",
      "cffi==1.14.2\n",
      "chardet==3.0.4\n",
      "colorama==0.4.3\n",
      "decorator==4.4.2\n",
      "defusedxml==0.6.0\n",
      "entrypoints==0.3\n",
      "gast==0.2.2\n",
      "google-auth==1.21.1\n",
      "google-auth-oauthlib==0.4.1\n",
      "google-pasta==0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 20.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grpcio==1.31.0\n",
      "h5py==2.10.0\n",
      "idna==2.10\n",
      "importlib-metadata==1.7.0\n",
      "ipykernel==5.3.4\n",
      "ipython==7.16.1\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.5.1\n",
      "jedi==0.17.2\n",
      "Jinja2==2.11.2\n",
      "joblib==0.16.0\n",
      "jsonschema==3.2.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==6.1.7\n",
      "jupyter-console==6.2.0\n",
      "jupyter-core==4.6.3\n",
      "Keras==2.3.1\n",
      "Keras-Applications==1.0.8\n",
      "Keras-Preprocessing==1.1.2\n",
      "Markdown==3.2.2\n",
      "MarkupSafe==1.1.1\n",
      "mistune==0.8.4\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.0.7\n",
      "notebook==6.1.4\n",
      "numpy==1.19.1\n",
      "oauthlib==3.1.0\n",
      "opt-einsum==3.3.0\n",
      "packaging==20.4\n",
      "pandas==1.0.3\n",
      "pandocfilters==1.4.2\n",
      "parso==0.7.1\n",
      "pickleshare==0.7.5\n",
      "prometheus-client==0.8.0\n",
      "prompt-toolkit==3.0.7\n",
      "protobuf==3.13.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycparser==2.20\n",
      "Pygments==2.6.1\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.17.2\n",
      "python-dateutil==2.8.1\n",
      "pytz==2020.1\n",
      "pywin32==228\n",
      "pywinpty==0.5.7\n",
      "PyYAML==5.3.1\n",
      "pyzmq==19.0.2\n",
      "qtconsole==4.7.7\n",
      "QtPy==1.9.0\n",
      "requests==2.24.0\n",
      "requests-oauthlib==1.3.0\n",
      "rsa==4.6\n",
      "scikit-learn==0.23.2\n",
      "scipy==1.5.2\n",
      "Send2Trash==1.5.0\n",
      "six==1.15.0\n",
      "sklearn==0.0\n",
      "tensorboard==2.0.2\n",
      "tensorflow==2.0.0\n",
      "tensorflow-estimator==2.0.1\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.3\n",
      "testpath==0.4.4\n",
      "threadpoolctl==2.1.0\n",
      "tornado==6.0.4\n",
      "traitlets==4.3.3\n",
      "urllib3==1.25.10\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "Werkzeug==1.0.1\n",
      "widgetsnbextension==3.5.1\n",
      "wrapt==1.12.1\n",
      "zipp==3.1.0\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
